{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "Para entrenar correctamente al modelo de *Machine Learning* es necesario recordar el flujo de trabajo dictado en el documento principal. La  \n",
    "\n",
    "En una primera instancia, debemos cargar nuestro set de datos y eliminar las filas repetidas, esto se debe realizar para evitar que el modelo memorice los datos y pueda realizar buenas predicciones. Para manejar el set de datos, utilizaremos la librería Pandas. \n",
    "\n",
    "Una vez cargado el set de datos, hay que hacer un breve analisis de cada columna para determinar su tratamiento en particular. En un vistazo rápido, podemos observar que desde la columnas 4 (C#) hasta la columna 17 (NoSQL) estan compuestas por datos numericos y toman valores cero (0) o uno (1); estas 13 columnas no van a necesitar ser procesadas. Por otra parte, la columna \"Experiencia\" tambien está compuesta por valores numericos enteros, pero estos valores puden variar desde 0 hasta 20. La diferencia entre estos valores es muy grande, y si le introducimos estos valores al modelo, sin procesarlos anteriormente, le "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos la librería Pandas para manejar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos el dataset y eliminamos las filas repetidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"candidatos.csv\")\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos las herramientas necesarias para procesar las columnas categóricas\n",
    "\n",
    "#### MinMaxScaler para la variable \"Experiencia\",  OrdinalEncoder para la variable \"Educación\" y \"Aptitud\",  OneHotEncoder para la variable \"Área\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "educacion = [\"Ninguna\",\"Tecnicatura\",\"Licenciatura\",\"Ingeniería\"]\n",
    "aptitud = [\"No apto\", \"Apto\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler()\n",
    "edu_encoder = OrdinalEncoder(categories=[educacion])\n",
    "apt_encoder = OrdinalEncoder(categories=[aptitud])\n",
    "ohe = OneHotEncoder(sparse_output=False).set_output(transform=\"pandas\")\n",
    "\n",
    "data[[\"Experiencia\"]] = mms.fit_transform(data[[\"Experiencia\"]])\n",
    "data[[\"Aptitud\"]] = apt_encoder.fit_transform(data[[\"Aptitud\"]])\n",
    "data[[\"Educación\"]] = edu_encoder.fit_transform(data[[\"Educación\"]])\n",
    "\n",
    "area_encoded = ohe.fit_transform(data[[\"Área\"]])\n",
    "data = pd.concat([data, area_encoded], axis=1).drop(columns=[\"Área\"])\n",
    "data.rename(columns={\n",
    "    \"Área_Desarrollo Móvil\": \"Desarrollo Movil\",\n",
    "    \"Área_Desarrollo Web\": \"Desarrollo Web\",\n",
    "    \"Área_Desarrollo de Juegos\": \"Desarrollo de Juegos\",\n",
    "    },\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En la etapa de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(columns=[\"Puntos\",\"Aptitud\"])\n",
    "y = data[\"Aptitud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "}\n",
    "\n",
    "accuracy_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LogisticRegression on test data: 0.9144654088050315\n",
      "Exactitud promedio entrenamiento: 0.9212725802102992\n",
      "Exactitud promedio validación: 0.9144654088050315\n",
      "Datos reales:\n",
      " 23847    0.0\n",
      "12063    0.0\n",
      "842      1.0\n",
      "330      0.0\n",
      "9422     1.0\n",
      "        ... \n",
      "25233    1.0\n",
      "13333    1.0\n",
      "24840    0.0\n",
      "25226    1.0\n",
      "3118     0.0\n",
      "Name: Aptitud, Length: 1590, dtype: float64\n",
      "Datos predichos:\n",
      " [0. 0. 1. ... 0. 1. 0.]\n",
      "Accuracy of DecisionTreeClassifier on test data: 0.9572327044025157\n",
      "Exactitud promedio entrenamiento: 1.0\n",
      "Exactitud promedio validación: 0.9572327044025157\n",
      "Datos reales:\n",
      " 23847    0.0\n",
      "12063    0.0\n",
      "842      1.0\n",
      "330      0.0\n",
      "9422     1.0\n",
      "        ... \n",
      "25233    1.0\n",
      "13333    1.0\n",
      "24840    0.0\n",
      "25226    1.0\n",
      "3118     0.0\n",
      "Name: Aptitud, Length: 1590, dtype: float64\n",
      "Datos predichos:\n",
      " [0. 0. 1. ... 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores[model_name] = accuracy\n",
    "    print(f'Accuracy of {model_name} on test data: {accuracy}')\n",
    "    print(f\"Exactitud promedio entrenamiento: {model.score(x_train,y_train)}\")\n",
    "    print(f\"Exactitud promedio validación: {model.score(x_test, y_test)}\")\n",
    "    print(\"Datos reales:\\n\", y_test)\n",
    "    print(\"Datos predichos:\\n\", y_pred)\n",
    "    with open(f\"../models/{model_name}.joblib\", \"wb\") as f:\n",
    "        dump(model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
