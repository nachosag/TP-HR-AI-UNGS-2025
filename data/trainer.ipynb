{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Clasificaci√≥n de candidatos con *Machine Learning*\n",
    "\n",
    "## Introducci√≥n üìå\n",
    "Se sigue un flujo de trabajo cl√°sico de Machine Learning: carga y limpieza del dataset, preprocesamiento de variables, entrenamiento de modelos, evaluaci√≥n y guardado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üêº 1. Carga de librer√≠as\n",
    "\n",
    "- Se importa la librer√≠a **Pandas**, la cual ser√° utilizada para cargar, limpiar y manipular el dataset de candidatos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìÑ 2. Cargar el dataset y eliminar duplicados\n",
    "- Se carga el archivo `candidatos.csv` como un DataFrame.\n",
    "- Se eliminan las filas duplicadas para evitar sesgo en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"candidatos.csv\")\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚öôÔ∏è 3. Importar herramientas de preprocesamiento\n",
    "- Se importan herramientas para escalar variables num√©ricas y codificar variables categ√≥ricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üè∑Ô∏è 4. Definici√≥n de categor√≠as para encoding ordinal\n",
    "- Se define el orden l√≥gico para las variables categ√≥ricas **Educaci√≥n** y **Aptitud** para que sean codificadas de forma ordinal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "educacion = [\"Ninguna\",\"Tecnicatura\",\"Licenciatura\",\"Ingenier√≠a\"]\n",
    "aptitud = [\"No apto\", \"Apto\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîÑ 5. Preprocesamiento del dataset\n",
    "- `MinMaxScaler`: Escala la **Experiencia** entre 0 y 1.\n",
    "- `OrdinalEncoder`: Codifica **Educaci√≥n** y **Aptitud** seg√∫n el √≥rden definido.\n",
    "- `OneHotEncoder`: Codifica la variable **√Årea** en m√∫ltiples columnas binarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler()\n",
    "edu_encoder = OrdinalEncoder(categories=[educacion])\n",
    "apt_encoder = OrdinalEncoder(categories=[aptitud])\n",
    "ohe = OneHotEncoder(sparse_output=False).set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se transforman las columnas mencionadas aplicando los m√©todos de escalado y codificaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"Experiencia\"]] = mms.fit_transform(data[[\"Experiencia\"]])\n",
    "data[[\"Aptitud\"]] = apt_encoder.fit_transform(data[[\"Aptitud\"]])\n",
    "data[[\"Educaci√≥n\"]] = edu_encoder.fit_transform(data[[\"Educaci√≥n\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se codifica la columna **√Årea** con One-Hot Encoding, se concatenan las nuevas columnas y se elimina la original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_encoded = ohe.fit_transform(data[[\"√Årea\"]])\n",
    "data = pd.concat([data, area_encoded], axis=1).drop(columns=[\"√Årea\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se renombran las columnas generadas por ``OneHotEncoder`` para hacerlas m√°s legibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={\n",
    "    \"√Årea_Desarrollo M√≥vil\": \"Desarrollo Movil\",\n",
    "    \"√Årea_Desarrollo Web\": \"Desarrollo Web\",\n",
    "    \"√Årea_Desarrollo de Juegos\": \"Desarrollo de Juegos\",\n",
    "    },\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ 6. Divisi√≥n de variables predictoras y objetivo\n",
    "- `x`: Variables independientes o predictores\n",
    "- `y`: Variable dependiente u objetivo (**Aptitud**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(columns=[\"Puntos\",\"Aptitud\"])\n",
    "y = data[\"Aptitud\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÇÔ∏è 7. Divisi√≥n de datos en entrenamiento y prueba\n",
    "Se dividen los datos en:\n",
    "- **Entrenamiento** (70%)\n",
    "- **Prueba/validaci√≥n** (30%) <br/>\n",
    "Usando una semilla (`random_state=42` para reproducibilidad.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ 8. Definici√≥n de modelos de ML\n",
    "Se importan dos algor√≠tmos:\n",
    "- Regresi√≥n Log√≠stica\n",
    "- √Årbol de Decisi√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crean los modelos y un diccionario para almacenar sus m√©tricas de desempe√±o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "}\n",
    "\n",
    "accuracy_scores = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìä 9. Evaluaci√≥n, impresi√≥n y guardado de modelos\n",
    "Se importa la m√©trica de **exactitud** (`acuracy_score`) y la funci√≥n para guardar los modelos entrenados (`dump`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada modelo:\n",
    "1. Se entrena (`fit`).\n",
    "2. Se predice sobre los datos de prueba.\n",
    "3. Se calcula la **exactitud** y se guarda.\n",
    "4. Se imprime el desempe√±o del modelo tanto en entrenamiento como en validaci√≥n, adem√°s de comparar los valores reales con los predichos.\n",
    "5. Cada modelo se guarda como archivo `.joblib` en la carpeta `../models/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LogisticRegression on test data: 0.9144654088050315\n",
      "Exactitud promedio entrenamiento: 0.9212725802102992\n",
      "Exactitud promedio validaci√≥n: 0.9144654088050315\n",
      "Datos reales:\n",
      " 23847    0.0\n",
      "12063    0.0\n",
      "842      1.0\n",
      "330      0.0\n",
      "9422     1.0\n",
      "        ... \n",
      "25233    1.0\n",
      "13333    1.0\n",
      "24840    0.0\n",
      "25226    1.0\n",
      "3118     0.0\n",
      "Name: Aptitud, Length: 1590, dtype: float64\n",
      "Datos predichos:\n",
      " [0. 0. 1. ... 0. 1. 0.]\n",
      "Accuracy of DecisionTreeClassifier on test data: 0.9578616352201258\n",
      "Exactitud promedio entrenamiento: 1.0\n",
      "Exactitud promedio validaci√≥n: 0.9578616352201258\n",
      "Datos reales:\n",
      " 23847    0.0\n",
      "12063    0.0\n",
      "842      1.0\n",
      "330      0.0\n",
      "9422     1.0\n",
      "        ... \n",
      "25233    1.0\n",
      "13333    1.0\n",
      "24840    0.0\n",
      "25226    1.0\n",
      "3118     0.0\n",
      "Name: Aptitud, Length: 1590, dtype: float64\n",
      "Datos predichos:\n",
      " [0. 0. 1. ... 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores[model_name] = accuracy\n",
    "    \n",
    "    print(f'Accuracy of {model_name} on test data: {accuracy}')\n",
    "    print(f\"Exactitud promedio entrenamiento: {model.score(x_train,y_train)}\")\n",
    "    print(f\"Exactitud promedio validaci√≥n: {model.score(x_test, y_test)}\")\n",
    "    print(\"Datos reales:\\n\", y_test)\n",
    "    print(\"Datos predichos:\\n\", y_pred)\n",
    "    \n",
    "    with open(f\"../models/{model_name}.joblib\", \"wb\") as f:\n",
    "        dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se imprime por consola el mejor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç El mejor modelo fue: DecisionTreeClassifier\n",
      "‚úÖ Exactitud: 0.9578616352201258\n"
     ]
    }
   ],
   "source": [
    "mejor_modelo = max(accuracy_scores, key=accuracy_scores.get)\n",
    "print(\"\\nüîç El mejor modelo fue:\", mejor_modelo)\n",
    "print(\"‚úÖ Exactitud:\", accuracy_scores[mejor_modelo])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
